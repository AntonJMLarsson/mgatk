from os.path import join
import os
import subprocess
import shutil
import pysam

configfile: config["cfp"]     
           
# Parse the configuration variables
indir = config["input_directory"]
outdir = config["output_directory"]
mitoQual = config["mitoQual"]
mito_genome = config["mito_genome"]
mito_length = config["mito_length"]
fasta_file = config["fasta_file"]
script_dir = config["script_dir"]
skip_indels = config["skip_indels"]
keep_duplicates = config["keep_duplicates"]
filtered_sorted = config["filtered_sorted"]
clipL = config["clipl"]
clipR = config["clipr"]

# Software paths
bcftools = "bcftools"
java = "java"
samtools = "samtools"
tabix = "tabix"
python = shutil.which("python")

# Script calls
filtClipBam = script_dir + "/bin/filterClipBam.py"
MarkDuplicatesCall = java + " -jar " + script_dir + "/bin/MarkDuplicates.jar"

# A Snakemake regular expression matching the bam files that were all aligned
SAMPLES, = glob_wildcards(join(outdir, ".internal/samples/{sample}.bam.txt"))

bamtxtin = '{sample}.bam.txt'

rule all:
	input:
		outdir + "/qc/depth/all.txt"

rule filter_sort:
	input:
		txtin = join(outdir + "/.internal/samples", bamtxtin)
	output:
		bam = outdir + "/temp_bam/ready/{sample}.qc.bam",
		bai = outdir + "/temp_bam/ready/{sample}.qc.bam.bai"
	threads: 1
	run:
		rmlog = output.bam.replace(".qc.bam", ".rmdups.logs").replace("/temp_bam/ready/", "/logs/rmdupslogs/")
		with open(input.txtin) as f: bamfilepath = f.read()
		
		# User likes the .bam files the way they are though we may need to filter duplicates
		if(filtered_sorted):
			if(keep_duplicates):
				shutil.copyfile(bamfilepath, output.bam)
			else:
				mdc_long = MarkDuplicatesCall + " INPUT="+bamfilepath+" OUTPUT="+output.bam+" METRICS_FILE="+rmlog+" REMOVE_DUPLICATES=true VALIDATION_STRINGENCY=SILENT"
				os.system(mdc_long)

		# Do some filtering, clipping, and sorting
		else:
			prepbam = output.bam.replace(".qc.bam", ".prep.bam").replace("/temp_bam/ready/", "/temp_bam/temp/")
			if(keep_duplicates):
				fcb_call = python + " " + filtClipBam + " " + bamfilepath + " " + clipL + " -" + clipR + " " + mito_genome + " | " + samtools + " sort -n - | " + samtools + " fixmate - " + prepbam
				os.system(fcb_call)

			else:
				filtbam = output.bam.replace(".qc.bam", ".filt.bam").replace("/temp_bam/ready/", "/temp_bam/temp/")
				fcb_call = python + " " + filtClipBam + " " + bamfilepath + " " + clipL + " -" + clipR + " " + mito_genome + " | " + samtools + " sort -n - | " + samtools + " fixmate - " + filtbam
				os.system(fcb_call)
				
				rmdupbam = filtbam.replace(".filt.bam", ".rmdup.bam")
				pysam.sort("-o", rmdupbam, filtbam)
				mdc_long = MarkDuplicatesCall + " INPUT="+rmdupbam+" OUTPUT="+prepbam+" METRICS_FILE="+rmlog+" REMOVE_DUPLICATES=true VALIDATION_STRINGENCY=SILENT"
				os.system(mdc_long)		
			pysam.sort("-o", output.bam, prepbam)
			
		pysam.index(output.bam)

rule get_depth_bq_baq:
	input:
		bam = outdir + "/temp_bam/ready/{sample}.qc.bam"
	output:
		depth = outdir + "/qc/depth/{sample}.Q0.depth.txt", 
		baq = outdir + "/qc/BAQ/{sample}.Q0.BAQ.txt", 
		bq = outdir + "/qc/BQ/{sample}.Q0.BQ.txt"
	threads: 1
	run:
		bamfilepath = input.bam
		
		# Depth
		os.system(samtools + " depth "+bamfilepath+" | awk '{sum+=$3} END {print sum/"+str(mito_length)+"}' > " + output.depth)
		
		# BAQ
		baq_vcf_gz = output.baq.replace(".Q0.BAQ.txt", ".Q0.BAQ.vcf.gz")
		stc = samtools + " mpileup -d8000 -f "+fasta_file+" -r "+mito_genome+" -Q0 -t AD,ADF,ADR "+skip_indels+"-v "+bamfilepath+" > " + baq_vcf_gz
		os.system(stc)
		os.system(tabix + " " + baq_vcf_gz)
		bcc = bcftools+" query -f '[%POS\tINFO/%I16\n]' "+baq_vcf_gz+" | sed -e 's/INFO\///g' -e 's/,/\t/g' > " + output.baq
		os.system(bcc)
		
		# BQ
		bq_vcf_gz = output.bq.replace(".Q0.BQ.txt", ".Q0.BQ.vcf.gz")
		stc2 = samtools + " mpileup -d8000 -f "+fasta_file+" -r "+mito_genome+" -Q0 -B -t AD,ADF,ADR "+skip_indels+"-v "+bamfilepath+" > " + bq_vcf_gz
		os.system(stc2)
		os.system(tabix + " " + bq_vcf_gz)
		bcc2 = bcftools+" query -f '[%POS\tINFO/%I16\n]' "+bq_vcf_gz+" | sed -e 's/INFO\///g' -e 's/,/\t/g' > " + output.bq
		os.system(bcc2)
		
rule make_depth_table:
	input:
		expand(outdir + "/qc/depth/{sample}.Q0.depth.txt", sample=SAMPLES)
	output:
		outdir + "/qc/depth/all.txt"
	threads: 1
	run: 
		with open(output[0], 'w') as f:
			for i in input:
				sample = i.replace(outdir+ "/qc/depth/", '').replace(".Q0.depth.txt", '')
				result = subprocess.run(['cat', i], stdout=subprocess.PIPE)
				f.write(sample + " " + result.stdout.strip().decode("utf-8") + "\n")
