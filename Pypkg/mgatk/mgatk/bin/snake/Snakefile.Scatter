from os.path import join
import os
import subprocess
import shutil
import pysam

configfile: config["cfp"]     
           
# Parse the configuration variables
indir = config["input_directory"]
outdir = config["output_directory"]
name = config["name"]
script_dir = config["script_dir"]
split_output = True

mito_genome = config["mito_genome"]
mito_length = str(config["mito_length"])
fasta_file = config["fasta_file"]

remove_duplicates = config["remove_duplicates"]
proper_paired = config["proper_paired"]
skip_indels = config["skip_indels"]

base_qual = str(config["base_qual"])
blacklist_percentile = config["blacklist_percentile"]

clipL = config["clipl"]
clipR = config["clipr"]
NHmax = config["NHmax"]
NMmax = config["NMmax"]

detailed_calls = config["detailed_calls"]

# Software paths
bcftools = "bcftools"
java = "java"
Rscript = "Rscript"
samtools = "samtools"
tabix = "tabix"
python = "python"

# Script locations
filtclip_py = script_dir + "/bin/filterClipBam.py"
detailedcall_py = script_dir + "/bin/detailedCalls.py"
DNAcounts_py = script_dir + "/bin/DNAcounts.py"

depthTableQuery_R = script_dir + "/bin/R/depthTableQuery.R"
makeBlacklist_R = script_dir + "/bin/R/makeBlacklist.R"

MarkDuplicatesCall = java + " -Xmx4000m  -jar " + script_dir + "/bin/MarkDuplicates.jar"

# A Snakemake regular expression matching the bam files that were all aligned
SAMPLES, = glob_wildcards(join(outdir, ".internal/samples/{sample}.bam.txt"))

bamtxtin = '{sample}.bam.txt'


rule all:
	input:
		outdir + "/final/" + name + ".depthTable.txt",
		outdir + "/final/" + name + ".blacklist.txt",
		outdir + "/final/" + name + ".A.txt.gz",
		outdir + "/final/" + name + ".C.txt.gz",
		outdir + "/final/" + name + ".G.txt.gz",
		outdir + "/final/" + name + ".T.txt.gz",
		outdir + "/final/" + name + ".coverage.txt.gz"

rule process_one_sample:
	input:
		txtin = join(outdir + "/.internal/samples", bamtxtin)
	output:
		bam = outdir + "/temp/ready_bam/{sample}.qc.bam",
		bai = outdir + "/temp/ready_bam/{sample}.qc.bam.bai",
		depth = outdir + "/qc/depth/{sample}.Q0.depth.txt", 
		A = outdir + "/temp/sparse_matrices/{sample}.A.txt",
		C = outdir + "/temp/sparse_matrices/{sample}.C.txt",
		G = outdir + "/temp/sparse_matrices/{sample}.G.txt",
		T = outdir + "/temp/sparse_matrices/{sample}.T.txt",
		cov = outdir + "/temp/sparse_matrices/{sample}.coverage.txt",
		baq = outdir + "/qc/BAQ/{sample}.Q0.BAQ.txt", 
#		bq = outdir + "/qc/BQ/{sample}.Q0.BQ.txt"
	threads: 1
	run:
		sample = output.bam.replace(outdir + "/temp/ready_bam/", "").replace(".qc.bam", "")
		with open(input.txtin) as f: bamfilepath = f.read()
		
		# File paths
		rmlog = output.bam.replace(".qc.bam", ".rmdups.log").replace("/temp/ready_bam/", "/logs/rmdupslogs/")
		filtlog = output.bam.replace(".qc.bam", ".filter.log").replace("/temp/ready_bam/", "/logs/filterlogs/")
		temp_bam0 = output.bam.replace(".qc.bam", ".temp0.bam").replace("/temp/ready_bam/", "/temp/temp_bam/")
		temp_bam1 = output.bam.replace(".qc.bam", ".temp1.bam").replace("/temp/ready_bam/", "/temp/temp_bam/")
		
		
		# Filter call
		pycall = " ".join([python, filtclip_py, bamfilepath, filtlog, clipL, "-"+clipR, mito_genome, NHmax, NMmax])
		
		if(len(proper_paired) > 0):
			pycallout = pycall + proper_paried + " > " + temp_bam0 # samtools
		else:
			pycallout = pycall+ " > " + temp_bam0
		os.system(pycallout)
		
		# Sort the filtered bam file
		pysam.sort("-o", temp_bam1, temp_bam0)
		pysam.index(temp_bam1)
		
		# Remove duplicates
		if remove_duplicates:
			mdc_long = MarkDuplicatesCall + " INPUT="+temp_bam1+" OUTPUT="+output.bam+" METRICS_FILE="+rmlog+" REMOVE_DUPLICATES=true VALIDATION_STRINGENCY=SILENT"
			os.system(mdc_long)
		else: # just move the previous output
			os.system("mv " + temp_bam1 + " " + output.bam)
			os.system("mv " + temp_bam1 + ".bai " + output.bai)
		pysam.index(output.bam)
		bamfilepath = output.bam
		
		# Get allele counts per sample / base pair
		prefix = outdir + "/temp/sparse_matrices/" + sample
		print(prefix)
		pycall = " ".join([python, DNAcounts_py, output.bam, prefix, mito_genome, mito_length, base_qual, sample])
		os.system(pycall)
		
		# Get depth the OG way
		os.system(samtools + " depth "+bamfilepath+" | awk '{sum+=$3} END {print sum/"+str(mito_length)+"}' > " + output.depth)
		
		# Get the BAQ for all variants
		baq_vcf_gz = output.baq.replace(".Q0.BAQ.txt", ".Q0.BAQ.vcf.gz").replace("/qc/BAQ/", "/temp/vcf/")
		stc = samtools + " mpileup -d8000 -f "+fasta_file+" -r "+mito_genome+" -Q0 -t AD,ADF,ADR "+skip_indels+"-v "+bamfilepath+" > " + baq_vcf_gz
		os.system(stc)
		os.system(tabix + " " + baq_vcf_gz)
		bcc = bcftools+" query -f '[%POS\tINFO/%I16\n]' "+baq_vcf_gz+" | sed -e 's/INFO\///g' -e 's/,/\t/g' > " + output.baq
		os.system(bcc)
		
		# BQ
#		bq_vcf_gz = output.bq.replace(".Q0.BQ.txt", ".Q0.BQ.vcf.gz").replace("/qc/BQ/", "/temp/vcf/")
#		stc2 = samtools + " mpileup -d8000 -f "+fasta_file+" -r "+mito_genome+" -Q0 -B -t AD,ADF,ADR "+skip_indels+"-v "+bamfilepath+" > " + bq_vcf_gz
#		os.system(stc2)
#		os.system(tabix + " " + bq_vcf_gz)
#		bcc2 = bcftools+" query -f '[%POS\tINFO/%I16\n]' "+bq_vcf_gz+" | sed -e 's/INFO\///g' -e 's/,/\t/g' > " + output.bq
#		os.system(bcc2)

rule make_depth_table:
	input:
		expand(outdir + "/qc/depth/{sample}.Q0.depth.txt", sample=SAMPLES)
	output:
		outdir + "/final/" + name + ".depthTable.txt"
	threads: 1
	run: 
		with open(output[0], 'w') as f:
			for i in input:
				sample = i.replace(outdir+ "/qc/depth/", '').replace(".Q0.depth.txt", '')
				result = subprocess.run(['cat', i], stdout=subprocess.PIPE)
				f.write(sample + " " + result.stdout.strip().decode("utf-8") + "\n")

rule make_final_sparse_matrices:
	input:
		As =expand(outdir + "/temp/sparse_matrices/{sample}.A.txt", sample=SAMPLES),
		Cs =expand(outdir + "/temp/sparse_matrices/{sample}.C.txt", sample=SAMPLES),
		Gs =expand(outdir + "/temp/sparse_matrices/{sample}.G.txt", sample=SAMPLES),
		Ts =expand(outdir + "/temp/sparse_matrices/{sample}.T.txt", sample=SAMPLES),
		Covs =expand(outdir + "/temp/sparse_matrices/{sample}.coverage.txt", sample=SAMPLES)
	output:
		A= outdir + "/final/" + name + ".A.txt.gz",
		C= outdir + "/final/" + name + ".C.txt.gz",
		G= outdir + "/final/" + name + ".G.txt.gz",
		T= outdir + "/final/" + name + ".T.txt.gz",
		Cov= outdir + "/final/" + name + ".coverage.txt.gz"
	threads: 1
	run: 
		def makeSM(iterableThing, l):
			for i in iterableThing:
				os.system("cat " + i + " >> " + outdir + "/final/" + name + "."+l+".txt")
			os.system("gzip " + outdir + "/final/" + name + "."+l+".txt")
			
		makeSM(input.As, "A")
		makeSM(input.Cs, "C")
		makeSM(input.Gs, "G")
		makeSM(input.Ts, "T")
		makeSM(input.Covs, "coverage")
		

rule make_blacklist:
	input:
		table = outdir + "/final/" + name + ".depthTable.txt"
	output:
		o1 = outdir + "/temp/" + name + ".samplesFor.blacklist.txt",
		allBAQ = outdir + "/temp/" + name + ".allBAQfor.blacklist.txt.gz",
		out = outdir + "/final/" + name + ".blacklist.txt"
	threads: 1
	run: 
		# Determine samples
		Rcall1 = " ".join([Rscript, depthTableQuery_R, input[0], output.o1, blacklist_percentile])
		os.system(Rcall1)
		
		# Cat together BAQ files
		with open(output.o1) as f:
			content = f.readlines()
		content = [x.strip() for x in content] 
		files = [outdir + "/qc/BAQ/" + s + ".Q0.BAQ.txt" for s in content]
		os.system("cat " + " ".join(files) + " | gzip > " + output.allBAQ)
		
		# Do the blacklist stuff
		Rcall2 = " ".join([Rscript, makeBlacklist_R, output.allBAQ, output.out, str(mito_length)])
		os.system(Rcall2)
